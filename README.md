# Support Vector Machine (SVM) Classification â€“ Internship Task 7

## ðŸ“Œ Overview
This project is part of my **AI & ML Internship** (Task 5), where I implemented **Support Vector Machines (SVM)** for binary classification using the **Breast Cancer dataset**.

The task includes:
- Training SVM with **Linear** and **RBF** kernels
- Visualizing decision boundaries (via PCA)
- Tuning hyperparameters (**C** and **gamma**)
- Evaluating the model using cross-validation

---

## ðŸ“‚ Dataset
- **Name:** Breast Cancer Dataset  
- **Source:** Provided as part of the internship  
- **Target:** Diagnosis (M = Malignant, B = Benign)

---

## ðŸ›  Tools & Libraries Used
- Python  
- Pandas  
- NumPy  
- Matplotlib  
- Seaborn  
- Scikit-learn  

---

## ðŸ“Š Steps Performed
1. **Load and Prepare Dataset** â€“ Removed unnecessary columns, mapped target labels to binary values.  
2. **Train/Test Split** â€“ Used `stratify = y` to maintain class balance in both sets.  
3. **Feature Scaling** â€“ Standardized features for better SVM performance.  
4. **SVM Training** â€“  
   - Linear Kernel  
   - RBF Kernel  
5. **Visualization** â€“ Reduced features to 2D with PCA and plotted decision boundaries.  
6. **Hyperparameter Tuning** â€“ Used `GridSearchCV` to find best `C` and `gamma` values.  
7. **Cross-Validation** â€“ Calculated average accuracy using k-fold CV.  

---

## ðŸ“ˆ Results
- **Linear Kernel Accuracy:** 96.49%  
- **RBF Kernel Accuracy:** 96.49%  
- **Best Parameters (RBF):** `C = X`, `gamma = X`  
- **Best Model Accuracy:** 98.24%  
- **Average CV Accuracy:** 62.74%  

---

## ðŸ“· Visualizations
- Decision Boundary Plot (PCA 2D projection)  
- Confusion Matrix Heatmap  

---

## ðŸ“š Key Learnings
- Difference between **Linear** and **RBF** kernels in SVM  
- Importance of scaling features in SVM models  
- How `C` controls margin size and misclassification tolerance  
- How `gamma` affects the RBF kernel's influence  
- Role of `stratify = y` in keeping class distributions balanced  
